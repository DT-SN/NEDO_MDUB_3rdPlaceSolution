{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qcGZJeA0AhR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HOMEディレクトリ設定(環境に合わせて変更してください)\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Google Colaboratoryの場合\n",
        "    HOME = Path(\"/content/drive/MyDrive/signate/NEDOG\")\n",
        "\n",
        "    # Google Driveをマウント\n",
        "    if not os.path.exists(\"/content/drive\"):\n",
        "        from google.colab import drive\n",
        "        drive.mount(\"/content/drive\")\n",
        "else:\n",
        "    # それ以外\n",
        "    HOME = Path(\"..\")\n",
        "\n",
        "# INPUT/WORKINGディレクトリ設定\n",
        "INPUT = HOME / \"input\"\n",
        "WORKING = HOME / \"working\""
      ],
      "metadata": {
        "id": "yYuFBXQF0Lta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter('ignore', FutureWarning)"
      ],
      "metadata": {
        "id": "XOGH9kZVtq2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "B2g8oh9R0SKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)"
      ],
      "metadata": {
        "id": "ZRwB5yC10SwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データ読み取り"
      ],
      "metadata": {
        "id": "H4RJIYo7BpNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr_emg_df = pd.read_pickle(WORKING / 'prep2_tr_emg.pickle')\n",
        "tr_vel_df = pd.read_pickle(WORKING / 'prep2_tr_vel.pickle')\n",
        "ts_emg_df = pd.read_pickle(WORKING / 'prep2_ts_emg.pickle')"
      ],
      "metadata": {
        "id": "SfrHz_DUO4fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# スロープ上り下り区別用フラグ(均等にするため閾値は-10とする)\n",
        "tr_dir_df = tr_vel_df.groupby(['subject','trial'])['vel_x'].apply(\n",
        "    lambda x: x.sum() > -10\n",
        ").rename('dir').reset_index()\n",
        "tr_vel_df = tr_vel_df.merge(tr_dir_df, on=['subject','trial'])"
      ],
      "metadata": {
        "id": "TgeoOzsEFgvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 学習/推論用"
      ],
      "metadata": {
        "id": "-0NyyC1IOA38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'verbosity': -1,\n",
        "    'random_state': 41,\n",
        "    'learning_rate': 0.05,\n",
        "    'boosting_type': 'gbdt',\n",
        "\n",
        "    #'lambda_l1': 0.5103247316877605, 'lambda_l2': 0.015010593003038865,\n",
        "    #'num_leaves': 58, 'feature_fraction': 0.474875745099162,\n",
        "    #'bagging_fraction': 0.8775197693430815, 'bagging_freq': 9, 'min_child_samples': 22\n",
        "    'lambda_l1': 1.600428398027849, 'lambda_l2': 0.00011273908593669964,\n",
        "    'num_leaves': 152, 'feature_fraction': 0.3711806552896912,\n",
        "    'bagging_fraction': 0.9654375223160317, 'bagging_freq': 7, 'min_child_samples': 171\n",
        "}"
      ],
      "metadata": {
        "id": "7sgpCmDqOAed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# holdoutで学習/推論\n",
        "def train_holdout(x_train, y_train, x_valid, y_valid, params):\n",
        "    data_train = lgb.Dataset(data=x_train, label=y_train)\n",
        "    data_valid = lgb.Dataset(data=x_valid, label=y_valid)\n",
        "\n",
        "    model = lgb.train(\n",
        "        params, data_train, valid_sets=[data_valid],\n",
        "        num_boost_round=10000,\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(stopping_rounds=100, verbose=False)\n",
        "        ]\n",
        "    )\n",
        "    pred = model.predict(x_valid)\n",
        "\n",
        "    return pred, model"
      ],
      "metadata": {
        "id": "yw1t5_7PMW7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cross validationで学習/推論(学習専用データを設定可能)\n",
        "def train_cv(x_cross, y_cross, x_train, y_train, group, params, n=5):\n",
        "    models = []\n",
        "    oof = np.zeros(len(y_cross), dtype=np.float64)\n",
        "    kf = GroupKFold(n_splits=n)\n",
        "    for idx_train, idx_valid in tqdm(kf.split(x_cross, y_cross, group),total=n):\n",
        "        pred, model = train_holdout(\n",
        "            pd.concat([x_cross.iloc[idx_train], x_train], axis=0),\n",
        "            pd.concat([y_cross.iloc[idx_train], y_train], axis=0),\n",
        "            x_cross.iloc[idx_valid],\n",
        "            y_cross.iloc[idx_valid],\n",
        "            params\n",
        "        )\n",
        "        models.append(model)\n",
        "        oof[idx_valid] = pred\n",
        "    return oof, models"
      ],
      "metadata": {
        "id": "YshLqK16ELmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# スロープ上り下り分離CVによる学習/推論\n",
        "def train_predict(tr_emg_df, tr_vel_df, ts_emg_df, target_col, drop_cols, params, n_loop=1):\n",
        "    fd = tr_vel_df['dir']\n",
        "    f5 = tr_emg_df['subject'] == 5\n",
        "    f6 = tr_emg_df['subject'] == 6\n",
        "\n",
        "    train_cols = tr_emg_df.columns[~tr_emg_df.columns.isin(drop_cols)]\n",
        "    tr_pred = 0\n",
        "    ts_pred = 0\n",
        "    models = []\n",
        "    for i in tqdm(range(n_loop)):\n",
        "        seed_everything(41+i)\n",
        "        params['random_state'] = 41+i\n",
        "\n",
        "        tr_pred_sub = np.zeros(len(tr_vel_df), dtype=np.float64)\n",
        "        models_sub = []\n",
        "\n",
        "        # cross validation (上り)\n",
        "        f = fd & ~f5 & ~f6\n",
        "        group   = tr_emg_df.loc[ f, 'trial']\n",
        "        x_cross = tr_emg_df.loc[ f, train_cols]\n",
        "        y_cross = tr_vel_df.loc[ f, target_col]\n",
        "        x_train = tr_emg_df.loc[~f, train_cols]\n",
        "        y_train = tr_vel_df.loc[~f, target_col]\n",
        "        pred, models1 = train_cv(x_cross, y_cross, x_train, y_train, group, params)\n",
        "        tr_pred_sub[f] = pred\n",
        "        models_sub += models1\n",
        "\n",
        "        # cross validation (下り)\n",
        "        f = ~fd & ~f5 & ~f6\n",
        "        group   = tr_emg_df.loc[ f, 'trial']\n",
        "        x_cross = tr_emg_df.loc[ f, train_cols]\n",
        "        y_cross = tr_vel_df.loc[ f, target_col]\n",
        "        x_train = tr_emg_df.loc[~f, train_cols]\n",
        "        y_train = tr_vel_df.loc[~f, target_col]\n",
        "        pred, models2 = train_cv(x_cross, y_cross, x_train, y_train, group, params)\n",
        "        tr_pred_sub[f] = pred\n",
        "        models_sub += models2\n",
        "\n",
        "        x_train = tr_emg_df[train_cols]\n",
        "        y_train = tr_vel_df[target_col]\n",
        "\n",
        "        # holdout (リファレンスtrain側を予測)\n",
        "        x_valid = x_train[f5].copy()\n",
        "        x_valid['subject'] = 6\n",
        "        y_valid = y_train[f5]\n",
        "        pred, model = train_holdout(x_train[~f5], y_train[~f5], x_valid, y_valid, params)\n",
        "        tr_pred_sub[f5] = pred\n",
        "        models_sub.append(model)\n",
        "\n",
        "        # holdout (リファレンスtest側を予測)\n",
        "        x_valid = x_train[f6].copy()\n",
        "        x_valid['subject'] = 5\n",
        "        y_valid = y_train[f6]\n",
        "        pred, model = train_holdout(x_train[~f6], y_train[~f6], x_valid, y_valid, params)\n",
        "        tr_pred_sub[f6] = pred\n",
        "        models_sub.append(model)\n",
        "\n",
        "        # 全モデルでtestデータ推論\n",
        "        x_test = ts_emg_df[train_cols]\n",
        "        ts_pred_sub = 0\n",
        "        for model in models_sub:\n",
        "            ts_pred_sub += model.predict(x_test.values)\n",
        "        ts_pred_sub /= len(models_sub)\n",
        "\n",
        "        print(mean_squared_error(tr_vel_df[target_col].values, tr_pred_sub, squared=False))\n",
        "        tr_pred += tr_pred_sub / n_loop\n",
        "        ts_pred += ts_pred_sub / n_loop\n",
        "        models += models_sub\n",
        "    return tr_pred, ts_pred, models"
      ],
      "metadata": {
        "id": "3IVuL3uD_KG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 各加速度の学習/推論"
      ],
      "metadata": {
        "id": "4I05Q3Vyiy4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_loop = 1\n",
        "target_cols = ['acc_z','acc_x','acc_y','acc_r','acc_s','acc_c','acc_e']\n",
        "drop_cols = ['trial','time']"
      ],
      "metadata": {
        "id": "kU7-OPAxHFhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_preds = []\n",
        "ts_preds = []\n",
        "model_dict = {}\n",
        "for target_col in target_cols:\n",
        "    # 学習/推論\n",
        "    tr_pred, ts_pred, models = train_predict(\n",
        "        tr_emg_df, tr_vel_df, ts_emg_df,\n",
        "        target_col, drop_cols, params, n_loop=n_loop\n",
        "    )\n",
        "\n",
        "    # スコア計算\n",
        "    f = tr_vel_df['subject'] <= 4\n",
        "    score1 = mean_squared_error(tr_vel_df.loc[f, target_col].values, tr_pred[f], squared=False)\n",
        "    f = tr_vel_df['subject'] == 5\n",
        "    score2 = mean_squared_error(tr_vel_df.loc[f, target_col].values, tr_pred[f], squared=False)\n",
        "    f = tr_vel_df['subject'] == 6\n",
        "    score3 = mean_squared_error(tr_vel_df.loc[f, target_col].values, tr_pred[f], squared=False)\n",
        "    print(target_col, score1, score2, score3, (score1 + score2 + score3) / 3)\n",
        "\n",
        "    # z軸推論値は特徴量に追加\n",
        "    if target_col[-1] == 'z':\n",
        "        tr_emg_df[f'pred_{target_col}'] = tr_pred\n",
        "        ts_emg_df[f'pred_{target_col}'] = ts_pred\n",
        "\n",
        "    # 結果格納\n",
        "    tr_preds.append(pd.Series(tr_pred, name=f'pred_{target_col}'))\n",
        "    ts_preds.append(pd.Series(ts_pred, name=f'pred_{target_col}'))\n",
        "    model_dict[target_col] = models"
      ],
      "metadata": {
        "id": "J-JI1NkjHXJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 保存"
      ],
      "metadata": {
        "id": "MxjMzgR0kyYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr_pred_df = pd.concat(tr_preds, axis=1)\n",
        "tr_pred_df.to_pickle(WORKING / 'tr_pred_acc.pickle')\n",
        "ts_pred_df = pd.concat(ts_preds, axis=1)\n",
        "ts_pred_df.to_pickle(WORKING / 'ts_pred_acc.pickle')"
      ],
      "metadata": {
        "id": "eQQoNDe5kQcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "with open(WORKING / 'lgbm_acc.joblib', 'wb') as f:\n",
        "    joblib.dump(model_dict, f, compress=4)"
      ],
      "metadata": {
        "id": "NCVdpMw6I7qV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}