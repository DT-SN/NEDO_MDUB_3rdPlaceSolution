{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qcGZJeA0AhR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HOMEディレクトリ設定(環境に合わせて変更してください)\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Google Colaboratoryの場合\n",
        "    HOME = Path(\"/content/drive/MyDrive/signate/NEDOG\")\n",
        "\n",
        "    # Google Driveをマウント\n",
        "    if not os.path.exists(\"/content/drive\"):\n",
        "        from google.colab import drive\n",
        "        drive.mount(\"/content/drive\")\n",
        "else:\n",
        "    # それ以外\n",
        "    HOME = Path(\"..\")\n",
        "\n",
        "# INPUT/WORKINGディレクトリ設定\n",
        "INPUT = HOME / \"input\"\n",
        "WORKING = HOME / \"working\""
      ],
      "metadata": {
        "id": "yYuFBXQF0Lta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter('ignore', FutureWarning)"
      ],
      "metadata": {
        "id": "09Tz3wQ-xzR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import scipy.signal\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "B2g8oh9R0SKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)"
      ],
      "metadata": {
        "id": "ZRwB5yC10SwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データ読み取り"
      ],
      "metadata": {
        "id": "U_a_G4zC-YNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# スムージング関数\n",
        "def smoothing(df, col):\n",
        "    icol = df.columns.get_loc(col)\n",
        "    for i in range(len(df)//30):\n",
        "        df.iloc[i*30:(i+1)*30,icol] = scipy.signal.savgol_filter(\n",
        "            df.iloc[i*30:(i+1)*30,icol].values,9,1)"
      ],
      "metadata": {
        "id": "5DuYGk2m-hoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_emg_df = pd.read_pickle(WORKING / 'prep2_tr_emg.pickle')\n",
        "tr_vel_df = pd.read_pickle(WORKING / 'prep2_tr_vel.pickle')\n",
        "ts_emg_df = pd.read_pickle(WORKING / 'prep2_ts_emg.pickle')"
      ],
      "metadata": {
        "id": "SfrHz_DUO4fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# スロープ上り下り区別用フラグ(均等にするため閾値は-10とする)\n",
        "tr_dir_df = tr_vel_df.groupby(['subject','trial'])['vel_x'].apply(\n",
        "    lambda x: x.sum() > -10\n",
        ").rename('dir').reset_index()\n",
        "tr_vel_df = tr_vel_df.merge(tr_dir_df, on=['subject','trial'])"
      ],
      "metadata": {
        "id": "tMmaY21nCY-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 速度推論結果\n",
        "tr_pred_df = pd.concat([\n",
        "    pd.read_pickle(WORKING / 'tr_pred_vel.pickle'),\n",
        "    pd.read_pickle(WORKING / 'tr_pred_vel_1c_p6.pickle').rename(columns=lambda x: f'1c_p6 {x}'),\n",
        "    pd.read_pickle(WORKING / 'tr_pred_vel_1c_p10.pickle').rename(columns=lambda x: f'1c_p10 {x}'),\n",
        "    pd.read_pickle(WORKING / 'tr_pred_vel_1c_p15.pickle').rename(columns=lambda x: f'1c_p15 {x}'),\n",
        "    pd.read_pickle(WORKING / 'tr_pred_vel_fc_p5.pickle').rename(columns=lambda x: f'fc_p5 {x}'),\n",
        "    pd.read_pickle(WORKING / 'tr_pred_vel_fc_p6.pickle').rename(columns=lambda x: f'fc_p6 {x}'),\n",
        "    pd.read_pickle(WORKING / 'tr_pred_vel_fc_p10.pickle').rename(columns=lambda x: f'fc_p10 {x}'),\n",
        "], axis=1)\n",
        "ts_pred_df = pd.concat([\n",
        "    pd.read_pickle(WORKING / 'ts_pred_vel.pickle'),\n",
        "    pd.read_pickle(WORKING / 'ts_pred_vel_1c_p6.pickle').rename(columns=lambda x: f'1c_p6 {x}'),\n",
        "    pd.read_pickle(WORKING / 'ts_pred_vel_1c_p10.pickle').rename(columns=lambda x: f'1c_p10 {x}'),\n",
        "    pd.read_pickle(WORKING / 'ts_pred_vel_1c_p15.pickle').rename(columns=lambda x: f'1c_p15 {x}'),\n",
        "    pd.read_pickle(WORKING / 'ts_pred_vel_fc_p5.pickle').rename(columns=lambda x: f'fc_p5 {x}'),\n",
        "    pd.read_pickle(WORKING / 'ts_pred_vel_fc_p6.pickle').rename(columns=lambda x: f'fc_p6 {x}'),\n",
        "    pd.read_pickle(WORKING / 'ts_pred_vel_fc_p10.pickle').rename(columns=lambda x: f'fc_p10 {x}'),\n",
        "], axis=1)"
      ],
      "metadata": {
        "id": "H2s3sSSms834"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 鏡像データ判定\n",
        "tr_pred_df = pd.concat([tr_emg_df[['subject','trial']], tr_pred_df], axis=1)\n",
        "ts_pred_df = pd.concat([ts_emg_df[['subject','trial']], ts_pred_df], axis=1)\n",
        "tr_pred_df['mirror'] = tr_pred_df.index >= len(tr_pred_df)//2\n",
        "ts_pred_df['mirror'] = ts_pred_df.index >= len(ts_pred_df)//2"
      ],
      "metadata": {
        "id": "ZTy0_TfntZKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ラグ特徴量取得関数\n",
        "def add_lag_feature(df, lags):\n",
        "    dfs = [df]\n",
        "    for lag in lags:\n",
        "        lag_df = df.groupby(['subject','trial','mirror']).shift(lag).rename(\n",
        "            columns=lambda x: f'lag{lag} '+x\n",
        "        )\n",
        "        dfs.append(lag_df)\n",
        "    return pd.concat(dfs, axis=1)"
      ],
      "metadata": {
        "id": "pCmDH2c_Os2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ラグ特徴量\n",
        "tr_emg_df = add_lag_feature(\n",
        "    tr_pred_df, list(range(-1,-30,-4))+list(range(1,30,4))\n",
        ").drop(['mirror'], axis=1)\n",
        "ts_emg_df = add_lag_feature(\n",
        "    ts_pred_df, list(range(-1,-30,-4))+list(range(1,30,4))\n",
        ").drop(['mirror'], axis=1)"
      ],
      "metadata": {
        "id": "6oj_XPwROssm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 学習/推論用"
      ],
      "metadata": {
        "id": "u3K1zUd0Pm7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'verbosity': -1,\n",
        "    'random_state': 41,\n",
        "    'learning_rate': 0.05,\n",
        "    'boosting_type': 'gbdt',\n",
        "\n",
        "    'lambda_l1': 0.0005745634015777443, 'lambda_l2': 0.00449846482477556,\n",
        "    'num_leaves': 22, 'feature_fraction': 0.23432846627769258,\n",
        "    'bagging_fraction': 0.6041179032582583, 'bagging_freq': 8, 'min_child_samples': 33\n",
        "}"
      ],
      "metadata": {
        "id": "SOesA7chGyXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# holdoutで学習/推論\n",
        "def train_holdout(x_train, y_train, x_valid, y_valid, params):\n",
        "    data_train = lgb.Dataset(data=x_train, label=y_train)\n",
        "    data_valid = lgb.Dataset(data=x_valid, label=y_valid)\n",
        "\n",
        "    model = lgb.train(\n",
        "        params, data_train, valid_sets=[data_valid],\n",
        "        num_boost_round=10000,\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(stopping_rounds=100, verbose=False)\n",
        "        ]\n",
        "    )\n",
        "    pred = model.predict(x_valid)\n",
        "\n",
        "    return pred, model"
      ],
      "metadata": {
        "id": "gFSwzhD3Pmb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cross validationで学習/推論(学習専用データを設定可能)\n",
        "def train_cv(x_cross, y_cross, x_train, y_train, group, params, n=5):\n",
        "    models = []\n",
        "    oof = np.zeros(len(y_cross), dtype=np.float64)\n",
        "    kf = GroupKFold(n_splits=n)\n",
        "    for idx_train, idx_valid in tqdm(kf.split(x_cross, y_cross, group),total=n):\n",
        "        pred, model = train_holdout(\n",
        "            pd.concat([x_cross.iloc[idx_train], x_train], axis=0),\n",
        "            pd.concat([y_cross.iloc[idx_train], y_train], axis=0),\n",
        "            x_cross.iloc[idx_valid],\n",
        "            y_cross.iloc[idx_valid],\n",
        "            params\n",
        "        )\n",
        "        models.append(model)\n",
        "        oof[idx_valid] = pred\n",
        "    return oof, models"
      ],
      "metadata": {
        "id": "3VB9gB2HGuXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# スロープ上り下り分離CVによる学習/推論\n",
        "def train_predict(tr_emg_df, tr_vel_df, ts_emg_df, target_col, drop_cols, params, n_loop=1):\n",
        "    fd = tr_vel_df['dir']\n",
        "    f5 = tr_emg_df['subject'] == 5\n",
        "    f6 = tr_emg_df['subject'] == 6\n",
        "\n",
        "    train_cols = tr_emg_df.columns[~tr_emg_df.columns.isin(drop_cols)]\n",
        "    tr_pred = 0\n",
        "    ts_pred = 0\n",
        "    models = []\n",
        "    for i in tqdm(range(n_loop)):\n",
        "        seed_everything(41+i)\n",
        "        params['random_state'] = 41+i\n",
        "\n",
        "        tr_pred_sub = np.zeros(len(tr_vel_df), dtype=np.float64)\n",
        "        models_sub = []\n",
        "\n",
        "        # cross validation (上り)\n",
        "        f = fd & ~f5 & ~f6\n",
        "        group   = tr_emg_df.loc[ f, 'trial']\n",
        "        x_cross = tr_emg_df.loc[ f, train_cols]\n",
        "        y_cross = tr_vel_df.loc[ f, target_col]\n",
        "        x_train = tr_emg_df.loc[~f, train_cols]\n",
        "        y_train = tr_vel_df.loc[~f, target_col]\n",
        "        pred, models1 = train_cv(x_cross, y_cross, x_train, y_train, group, params)\n",
        "        tr_pred_sub[f] = pred\n",
        "        models_sub += models1\n",
        "\n",
        "        # cross validation (下り)\n",
        "        f = ~fd & ~f5 & ~f6\n",
        "        group   = tr_emg_df.loc[ f, 'trial']\n",
        "        x_cross = tr_emg_df.loc[ f, train_cols]\n",
        "        y_cross = tr_vel_df.loc[ f, target_col]\n",
        "        x_train = tr_emg_df.loc[~f, train_cols]\n",
        "        y_train = tr_vel_df.loc[~f, target_col]\n",
        "        pred, models2 = train_cv(x_cross, y_cross, x_train, y_train, group, params)\n",
        "        tr_pred_sub[f] = pred\n",
        "        models_sub += models2\n",
        "\n",
        "        x_train = tr_emg_df[train_cols]\n",
        "        y_train = tr_vel_df[target_col]\n",
        "\n",
        "        # holdout (リファレンスtrain側を予測)\n",
        "        x_valid = x_train[f5].copy()\n",
        "        x_valid['subject'] = 6\n",
        "        y_valid = y_train[f5]\n",
        "        pred, model = train_holdout(x_train[~f5], y_train[~f5], x_valid, y_valid, params)\n",
        "        tr_pred_sub[f5] = pred\n",
        "        models_sub.append(model)\n",
        "\n",
        "        # holdout (リファレンスtest側を予測)\n",
        "        x_valid = x_train[f6].copy()\n",
        "        x_valid['subject'] = 5\n",
        "        y_valid = y_train[f6]\n",
        "        pred, model = train_holdout(x_train[~f6], y_train[~f6], x_valid, y_valid, params)\n",
        "        tr_pred_sub[f6] = pred\n",
        "        models_sub.append(model)\n",
        "\n",
        "        # 全モデルでtestデータ推論\n",
        "        x_test = ts_emg_df[train_cols]\n",
        "        ts_pred_sub = 0\n",
        "        for model in models_sub:\n",
        "            ts_pred_sub += model.predict(x_test.values)\n",
        "        ts_pred_sub /= len(models_sub)\n",
        "\n",
        "        print(mean_squared_error(tr_vel_df[target_col].values, tr_pred_sub, squared=False))\n",
        "        tr_pred += tr_pred_sub / n_loop\n",
        "        ts_pred += ts_pred_sub / n_loop\n",
        "        models += models_sub\n",
        "    return tr_pred, ts_pred, models"
      ],
      "metadata": {
        "id": "3TRQ9z0F_x8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 各速度の学習/推論"
      ],
      "metadata": {
        "id": "4I05Q3Vyiy4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_loop = 4\n",
        "target_cols = ['vel_z','vel_x','vel_y','vel_r','vel_s','vel_c','vel_e']\n",
        "drop_cols = ['trial','time']"
      ],
      "metadata": {
        "id": "izhj_7VFPwjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_preds = []\n",
        "ts_preds = []\n",
        "model_dict = {}\n",
        "for target_col in target_cols:\n",
        "    # 学習/推論\n",
        "    tr_pred, ts_pred, models = train_predict(\n",
        "        tr_emg_df, tr_vel_df, ts_emg_df,\n",
        "        target_col, drop_cols, params, n_loop=n_loop\n",
        "    )\n",
        "\n",
        "    # スコア計算\n",
        "    f = tr_vel_df['subject'] <= 4\n",
        "    score1 = mean_squared_error(tr_vel_df.loc[f, target_col].values, tr_pred[f], squared=False)\n",
        "    f = tr_vel_df['subject'] == 5\n",
        "    score2 = mean_squared_error(tr_vel_df.loc[f, target_col].values, tr_pred[f], squared=False)\n",
        "    f = tr_vel_df['subject'] == 6\n",
        "    score3 = mean_squared_error(tr_vel_df.loc[f, target_col].values, tr_pred[f], squared=False)\n",
        "    print(target_col, score1, score2, score3, (score1 + score2 + score3) / 3)\n",
        "\n",
        "    # 結果格納\n",
        "    tr_preds.append(pd.Series(tr_pred, name=f'pred_{target_col}'))\n",
        "    ts_preds.append(pd.Series(ts_pred, name=f'pred_{target_col}'))\n",
        "    model_dict[target_col] = models"
      ],
      "metadata": {
        "id": "NFWJMz4osHBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 保存"
      ],
      "metadata": {
        "id": "MxjMzgR0kyYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tr_pred_vel_df = pd.concat(tr_preds, axis=1)\n",
        "tr_pred_vel_df.to_pickle(WORKING / 'tr_pred_vel_stacking.pickle')\n",
        "ts_pred_vel_df = pd.concat(ts_preds, axis=1)\n",
        "ts_pred_vel_df.to_pickle(WORKING / 'ts_pred_vel_stacking.pickle')"
      ],
      "metadata": {
        "id": "eQQoNDe5kQcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "with open(WORKING / 'lgbm_vel_stacking.joblib', 'wb') as f:\n",
        "    joblib.dump(model_dict, f, compress=4)"
      ],
      "metadata": {
        "id": "lo_KGm0DJUyI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}